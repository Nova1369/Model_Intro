# Model_Intro
Creating a model with Deep Learning

<br>
a.
Model 1: 4 hidden layers having 128, 64, 32, 16 number of neurons
respectively with activation function sigmoid, tanh, relu and selu respectively
and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as SGD
with batch size set to 32.

<br>
b.
Model 2: 4 hidden layers having 128, 64, 32, 16 number of neurons
respectively with activation function sigmoid, tanh, relu and selu respectively
and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Adam
with batch size set to 32.

<br>
c.
Model 3: 4 h idden layers having 128, 64, 32, 16 number of neurons
respectively with activation function sigmoid, tanh, relu and selu respectively
and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as
AdamW with learning rate 0.1 with batch size set to 32.

<br>
d.
Model 4: 4 hidden layers having 128, 64, 32, 16 number of neurons
respectively with activation function sigmoid, tanh, relu and selu respectively
and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Nadam
with learning rate 0.1 with batch size set to 32.

<br>
Finally hypertuning the parameters
